{"cells":[{"cell_type":"markdown","id":"4f55173d-ab6d-4cc6-bf38-7041a6e7c17b","metadata":{"id":"4f55173d-ab6d-4cc6-bf38-7041a6e7c17b"},"source":["# Computer Assignment 4: CNN Segmentation\n","## Alaqian Zafar - aaz7118\n","\n","## Table of Contents\n","- <a href='#p1a'>Part (a)</a>\n","- <a href='#p1b'>Part (b)</a>\n","- <a href='#p1c'>Part (c)</a>\n","- <a href='#p1d'>Part (d)</a>\n","- <a href='#p2a'>Part (e)</a>\n","- <a href='#p2b'>Part (f)</a>\n","- <a href='#p2c'>Part (g)</a>"]},{"cell_type":"code","execution_count":1,"id":"bd605007-4d11-487a-937e-870eb43f594f","metadata":{"id":"bd605007-4d11-487a-937e-870eb43f594f","executionInfo":{"status":"ok","timestamp":1681647629966,"user_tz":240,"elapsed":252,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"}}},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import cv2\n","%matplotlib inline"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","path = '/content/drive/MyDrive/ECE-GY 6123 Image and Video Processing/Computer Assignments/CA04/archive'"],"metadata":{"id":"VXkF1WtANXVY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681647650682,"user_tz":240,"elapsed":20718,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"}},"outputId":"a48abedc-9363-44b8-91f6-6a24e827a022"},"id":"VXkF1WtANXVY","execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","id":"cdd71cc3-68b0-4339-82ed-5f7a15a29902","metadata":{"id":"cdd71cc3-68b0-4339-82ed-5f7a15a29902"},"source":["<a id='p1a'></a>\n","##### (a) Cut the FudanPed dataset into an 80-10-10 train-val-test split.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"code","source":["def preprocess_image(image):\n","    # pad the image with zeros to make it square\n","    image = cv2.copyMakeBorder(\n","        image,\n","        0, \n","        max(image.shape) - image.shape[0], \n","        0, \n","        max(image.shape) - image.shape[1],\n","        cv2.BORDER_CONSTANT, \n","        None, \n","        value = 0)\n","    \n","    # resize the image to 64 x 64\n","    image = cv2.resize(image, (128,128))\n","\n","    # reshape the image to have channel first\n","    #image = np.transpose(image, (2, 0, 1))\n","    return image"],"metadata":{"id":"yRZlE58BLylM","executionInfo":{"status":"ok","timestamp":1681647650682,"user_tz":240,"elapsed":3,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"}}},"id":"yRZlE58BLylM","execution_count":3,"outputs":[]},{"cell_type":"code","source":["import os\n","import torch\n","image_paths = sorted(os.listdir(path+\"/PNGImages\"))\n","mask_paths = sorted(os.listdir(path+\"/PedMasks\"))\n","\n","images = []\n","masks = []\n","for i, (image_path, mask_path) in enumerate(zip(image_paths, mask_paths)):\n","    image_path = os.path.join(path, \"PNGImages\", image_path)\n","    image = cv2.imread(image_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    images.append(preprocess_image(image))\n","    \n","    mask_path = os.path.join(path, \"PedMasks\", mask_path)\n","    mask = cv2.imread(mask_path, 0)\n","    masks.append(preprocess_image(mask))"],"metadata":{"id":"7pLVDuBjkZp7","executionInfo":{"status":"ok","timestamp":1681648012213,"user_tz":240,"elapsed":6347,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"}}},"id":"7pLVDuBjkZp7","execution_count":5,"outputs":[]},{"cell_type":"markdown","id":"33284490-af37-49c1-a5bd-c7d48472fcfc","metadata":{"tags":[],"id":"33284490-af37-49c1-a5bd-c7d48472fcfc"},"source":["<a id='p1b'></a>\n","##### (b) Apply data augmentation to your dataset during training and show an example of your data augmentation in your report.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"code","source":["images = [torch.from_numpy(item).float() for item in images]"],"metadata":{"id":"GxzoyQCWOS2V","executionInfo":{"status":"ok","timestamp":1681648088672,"user_tz":240,"elapsed":190,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"}}},"id":"GxzoyQCWOS2V","execution_count":6,"outputs":[]},{"cell_type":"markdown","id":"b1d3219f-8a19-461e-8147-acdc6e77deda","metadata":{"tags":[],"id":"b1d3219f-8a19-461e-8147-acdc6e77deda"},"source":["<a id='p1c'></a>\n","##### (c) Implement and train a CNN for binary segmentation on your train split. Describe your network architecture2, loss function, and any training hyper-parameters. You may implement any architecture you'd like, **but the implementation must be your own code.**\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"markdown","id":"6e1f0531-2aa0-4daf-9f8a-9315f9257e79","metadata":{"id":"6e1f0531-2aa0-4daf-9f8a-9315f9257e79"},"source":["<a id='p1d'></a>\n","##### (d) Report training loss, validation loss, and validation DICE curves. Comment on any overfitting or underfitting observed.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"markdown","id":"f2b0e596-7345-4eaa-8e9d-de9801d5b8fa","metadata":{"id":"f2b0e596-7345-4eaa-8e9d-de9801d5b8fa"},"source":["<a id='p2a'></a>\n","##### (e) Report the average dice score over your test-set. **You should be able to achieve a score of around 0.7 or better**.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"markdown","id":"88d56e64-544c-439f-a474-6b24f5e2d93f","metadata":{"tags":[],"id":"88d56e64-544c-439f-a474-6b24f5e2d93f"},"source":["<a id='p2b'></a>\n","##### (f) Show at least 3 example segmentations (i.e. show the RGB image, mask, and RGB image X mask for 3 samples) from your training data and 3 from your testing data. Comment on the generalization capabilities of your trained network.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"markdown","id":"e3de73fb-1143-4c0f-acbe-642cbdfb0b96","metadata":{"tags":[],"id":"e3de73fb-1143-4c0f-acbe-642cbdfb0b96"},"source":["<a id='p2c'></a>\n","##### (g) Show at least 1 example segmentation on an input image **<ins>not</ins> from the FudanPed dataset**. Again, comment on the generalization capabilities of your network with respect to this \"out-of-distribution\" image.\n","\n","[Table of Contents](#Table-of-Contents)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"colab":{"provenance":[],"collapsed_sections":["33284490-af37-49c1-a5bd-c7d48472fcfc","b1d3219f-8a19-461e-8147-acdc6e77deda","6e1f0531-2aa0-4daf-9f8a-9315f9257e79","f2b0e596-7345-4eaa-8e9d-de9801d5b8fa","88d56e64-544c-439f-a474-6b24f5e2d93f","e3de73fb-1143-4c0f-acbe-642cbdfb0b96"]},"gpuClass":"standard"},"nbformat":4,"nbformat_minor":5}