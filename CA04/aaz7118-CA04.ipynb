{"cells":[{"cell_type":"markdown","id":"4f55173d-ab6d-4cc6-bf38-7041a6e7c17b","metadata":{"id":"4f55173d-ab6d-4cc6-bf38-7041a6e7c17b"},"source":["# Computer Assignment 4: CNN Segmentation\n","## Alaqian Zafar - aaz7118\n","\n","## Table of Contents\n","- <a href='#p1a'>Part (a)</a>\n","- <a href='#p1b'>Part (b)</a>\n","- <a href='#p1c'>Part (c)</a>\n","- <a href='#p1d'>Part (d)</a>\n","- <a href='#p2a'>Part (e)</a>\n","- <a href='#p2b'>Part (f)</a>\n","- <a href='#p2c'>Part (g)</a>"]},{"cell_type":"code","execution_count":1,"id":"bd605007-4d11-487a-937e-870eb43f594f","metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1681647629966,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"},"user_tz":240},"id":"bd605007-4d11-487a-937e-870eb43f594f"},"outputs":[],"source":["import os\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torch\n","\n","%matplotlib inline"]},{"cell_type":"code","execution_count":2,"id":"VXkF1WtANXVY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":20718,"status":"ok","timestamp":1681647650682,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"},"user_tz":240},"id":"VXkF1WtANXVY","outputId":"a48abedc-9363-44b8-91f6-6a24e827a022"},"outputs":[],"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive')\n","    path = '/content/drive/MyDrive/ECE-GY 6123 Image and Video Processing/Computer Assignments/CA04/archive'\n","except:\n","    path = 'archive'"]},{"cell_type":"markdown","id":"cdd71cc3-68b0-4339-82ed-5f7a15a29902","metadata":{"id":"cdd71cc3-68b0-4339-82ed-5f7a15a29902"},"source":["<a id='p1a'></a>\n","##### (a) Cut the FudanPed dataset into an 80-10-10 train-val-test split.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"code","execution_count":3,"id":"yRZlE58BLylM","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1681647650682,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"},"user_tz":240},"id":"yRZlE58BLylM"},"outputs":[],"source":["def preprocess_image(image):\n","    # pad the image with zeros to make it square\n","    image = cv2.copyMakeBorder(\n","        image,\n","        0, \n","        max(image.shape) - image.shape[0], \n","        0, \n","        max(image.shape) - image.shape[1],\n","        cv2.BORDER_CONSTANT, \n","        None, \n","        value = 0)\n","    \n","    # resize the image to 64 x 64\n","    image = cv2.resize(image, (128,128))\n","\n","    # reshape the image to have channel first\n","    #image = np.transpose(image, (2, 0, 1))\n","    return image"]},{"cell_type":"code","execution_count":4,"id":"7pLVDuBjkZp7","metadata":{"executionInfo":{"elapsed":6347,"status":"ok","timestamp":1681648012213,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"},"user_tz":240},"id":"7pLVDuBjkZp7"},"outputs":[],"source":["\n","image_paths = sorted(os.listdir(path+\"/PNGImages\"))\n","mask_paths = sorted(os.listdir(path+\"/PedMasks\"))\n","\n","images = []\n","masks = []\n","for i, (image_path, mask_path) in enumerate(zip(image_paths, mask_paths)):\n","    image_path = os.path.join(path, \"PNGImages\", image_path)\n","    image = cv2.imread(image_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","    images.append(preprocess_image(image))\n","    \n","    mask_path = os.path.join(path, \"PedMasks\", mask_path)\n","    mask = cv2.imread(mask_path, 0)\n","    masks.append(preprocess_image(mask))"]},{"cell_type":"markdown","id":"33284490-af37-49c1-a5bd-c7d48472fcfc","metadata":{"id":"33284490-af37-49c1-a5bd-c7d48472fcfc","tags":[]},"source":["<a id='p1b'></a>\n","##### (b) Apply data augmentation to your dataset during training and show an example of your data augmentation in your report.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"code","execution_count":5,"id":"GxzoyQCWOS2V","metadata":{"executionInfo":{"elapsed":190,"status":"ok","timestamp":1681648088672,"user":{"displayName":"Alaqian Zafar","userId":"09077679626904495344"},"user_tz":240},"id":"GxzoyQCWOS2V"},"outputs":[],"source":["images = [torch.from_numpy(item).float() for item in images]"]},{"cell_type":"markdown","id":"b1d3219f-8a19-461e-8147-acdc6e77deda","metadata":{"id":"b1d3219f-8a19-461e-8147-acdc6e77deda","tags":[]},"source":["<a id='p1c'></a>\n","##### (c) Implement and train a CNN for binary segmentation on your train split. Describe your network architecture2, loss function, and any training hyper-parameters. You may implement any architecture you'd like, **but the implementation must be your own code.**\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"markdown","id":"6e1f0531-2aa0-4daf-9f8a-9315f9257e79","metadata":{"id":"6e1f0531-2aa0-4daf-9f8a-9315f9257e79"},"source":["<a id='p1d'></a>\n","##### (d) Report training loss, validation loss, and validation DICE curves. Comment on any overfitting or underfitting observed.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"markdown","id":"f2b0e596-7345-4eaa-8e9d-de9801d5b8fa","metadata":{"id":"f2b0e596-7345-4eaa-8e9d-de9801d5b8fa"},"source":["<a id='p2a'></a>\n","##### (e) Report the average dice score over your test-set. **You should be able to achieve a score of around 0.7 or better**.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"markdown","id":"88d56e64-544c-439f-a474-6b24f5e2d93f","metadata":{"id":"88d56e64-544c-439f-a474-6b24f5e2d93f","tags":[]},"source":["<a id='p2b'></a>\n","##### (f) Show at least 3 example segmentations (i.e. show the RGB image, mask, and RGB image X mask for 3 samples) from your training data and 3 from your testing data. Comment on the generalization capabilities of your trained network.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"markdown","id":"e3de73fb-1143-4c0f-acbe-642cbdfb0b96","metadata":{"id":"e3de73fb-1143-4c0f-acbe-642cbdfb0b96","tags":[]},"source":["<a id='p2c'></a>\n","##### (g) Show at least 1 example segmentation on an input image **<ins>not</ins> from the FudanPed dataset**. Again, comment on the generalization capabilities of your network with respect to this \"out-of-distribution\" image.\n","\n","[Table of Contents](#Table-of-Contents)"]},{"cell_type":"code","execution_count":8,"id":"f6733ef6","metadata":{"tags":["run_all"]},"outputs":[{"name":"stderr","output_type":"stream","text":["[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n","[NbConvertApp] Converting notebook aaz7118-CA04.ipynb to html\n","[NbConvertApp] Writing 287941 bytes to aaz7118-CA04.html\n"]}],"source":["# Create a README.md from this notebook\n","!jupyter nbconvert --TagRemovePreprocessor.enabled=True --TagRemovePreprocessor.remove_cell_tags run_all aaz7118-CA04.ipynb --to html --template classic"]}],"metadata":{"colab":{"collapsed_sections":["33284490-af37-49c1-a5bd-c7d48472fcfc","b1d3219f-8a19-461e-8147-acdc6e77deda","6e1f0531-2aa0-4daf-9f8a-9315f9257e79","f2b0e596-7345-4eaa-8e9d-de9801d5b8fa","88d56e64-544c-439f-a474-6b24f5e2d93f","e3de73fb-1143-4c0f-acbe-642cbdfb0b96"],"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":5}
